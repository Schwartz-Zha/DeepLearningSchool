{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, RepeatVector, TimeDistributed\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):        \n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):        \n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):        \n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "MAXOUTPUTLEN = DIGITS + 1\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_random_digit():\n",
    "  return np.random.choice(list('0123456789'))  \n",
    "  \n",
    "def generate_number():\n",
    "  num_digits = np.random.randint(1, DIGITS + 1)  \n",
    "  return int(''.join( return_random_digit()\n",
    "                      for i in range(num_digits)))\n",
    "\n",
    "def data_generate(num_examples):\n",
    "  questions = []\n",
    "  expected = []\n",
    "  seen = set()\n",
    "  print('Generating data...')\n",
    "  while len(questions) < TRAINING_SIZE:      \n",
    "      a, b = generate_number(), generate_number()  \n",
    "      #Remove already seen elements\n",
    "      key = tuple(sorted((a, b)))\n",
    "      if key in seen:\n",
    "          continue\n",
    "      seen.add(key)\n",
    "      # Pad the data with spaces such that it is always MAXLEN.\n",
    "      q = '{}+{}'.format(a, b)\n",
    "      query = q + ' ' * (MAXLEN - len(q))\n",
    "      ans = str(a + b)\n",
    "      # Answers can be of maximum size DIGITS + 1.\n",
    "      ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "      questions.append(query)\n",
    "      expected.append(ans)\n",
    "  print('Total addition questions:', len(questions))\n",
    "  return questions, expected\n",
    "\n",
    "\n",
    "def encode_examples(questions,answers):\n",
    "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "  for i, sentence in enumerate(questions):\n",
    "      x[i] = ctable.encode(sentence, MAXLEN)\n",
    "  for i, sentence in enumerate(answers):\n",
    "      y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "  indices = np.arange(len(y))\n",
    "  np.random.shuffle(indices)\n",
    "  return x[indices],y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Training Data shape:\n",
      "X :  (45000, 7, 12)\n",
      "Y :  (45000, 4, 12)\n",
      "Sample Question(in decoded form) :  18+140  Sample Output :  158 \n"
     ]
    }
   ],
   "source": [
    "q,a = data_generate(TRAINING_SIZE)\n",
    "x,y = encode_examples(q,a)\n",
    "split_at = len(x) - len(x) // 10\n",
    "x_train, x_val, y_train, y_val = x[:split_at], x[split_at:],y[:split_at],y[split_at:]\n",
    "\n",
    "\n",
    "print('Training Data shape:')\n",
    "print('X : ', x_train.shape)\n",
    "print('Y : ', y_train.shape)\n",
    "\n",
    "print('Sample Question(in decoded form) : ', ctable.decode(x_train[0]),'Sample Output : ', ctable.decode(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6)\n",
      "(None, 3, 6)\n",
      "Shape of input :  (1, 10)\n",
      "Shape of output :  (1, 3, 6)\n",
      "Input :  [555 206 196 315 542 445 831 861 838  81]\n",
      "Output :  [[  12.334458  354.43985   760.5043   -576.0926   -408.6205   1022.52686 ]\n",
      " [  12.334458  354.43985   760.5043   -576.0926   -408.6205   1022.52686 ]\n",
      " [  12.334458  354.43985   760.5043   -576.0926   -408.6205   1022.52686 ]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#converts from 1*32 to 1 * 6\n",
    "model.add(Dense(6, input_dim=10))\n",
    "print(model.output_shape)\n",
    "#converts from 1*6 to 1*3*6\n",
    "model.add(RepeatVector(3))\n",
    "print(model.output_shape) \n",
    "input_array = np.random.randint(1000, size=(1, 10))\n",
    "print(\"Shape of input : \", input_array.shape)\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(\"Shape of output : \", output_array.shape)\n",
    "# note: `None` is the batch dimension\n",
    "print('Input : ', input_array[0])\n",
    "print('Output : ', output_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               18048     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 4, 128)            32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 52,492\n",
      "Trainable params: 52,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Hyperaparams\n",
    "RNN = layers.SimpleRNN\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#ENCODING\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(RepeatVector(MAXOUTPUTLEN))\n",
    "#DECODING\n",
    "for _ in range(LAYERS):    \n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 3s 71us/step - loss: 1.6711 - acc: 0.3911 - val_loss: 1.5362 - val_acc: 0.4377\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 1.4392 - acc: 0.4677 - val_loss: 1.3404 - val_acc: 0.5006\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 1.2382 - acc: 0.5363 - val_loss: 1.1439 - val_acc: 0.5653\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 1.0408 - acc: 0.6056 - val_loss: 0.9668 - val_acc: 0.6302\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.8598 - acc: 0.6708 - val_loss: 0.8127 - val_acc: 0.6817\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.7079 - acc: 0.7310 - val_loss: 0.6780 - val_acc: 0.7407\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.5997 - acc: 0.7769 - val_loss: 0.5878 - val_acc: 0.7820\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.5181 - acc: 0.8123 - val_loss: 0.5048 - val_acc: 0.8191\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.4640 - acc: 0.8337 - val_loss: 0.4574 - val_acc: 0.8367\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 3s 59us/step - loss: 0.4143 - acc: 0.8531 - val_loss: 0.4272 - val_acc: 0.8412\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 3s 64us/step - loss: 0.3748 - acc: 0.8696 - val_loss: 0.3717 - val_acc: 0.8679\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3456 - acc: 0.8805 - val_loss: 0.3550 - val_acc: 0.8716\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3174 - acc: 0.8901 - val_loss: 0.3364 - val_acc: 0.8810\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.2922 - acc: 0.8997 - val_loss: 0.3456 - val_acc: 0.8728\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.2732 - acc: 0.9065 - val_loss: 0.2809 - val_acc: 0.9020\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.2601 - acc: 0.9105 - val_loss: 0.3042 - val_acc: 0.8841\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 3s 64us/step - loss: 0.2446 - acc: 0.9157 - val_loss: 0.2737 - val_acc: 0.9010\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.2378 - acc: 0.9181 - val_loss: 0.2850 - val_acc: 0.8954\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.2106 - acc: 0.9300 - val_loss: 0.2298 - val_acc: 0.9219\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.2015 - acc: 0.9323 - val_loss: 0.2475 - val_acc: 0.9114\n",
      "Finished iteration  1\n",
      "Question 567+58  True 625  Guess 625  Good job\n",
      "Question 621+118 True 739  Guess 839  Fail\n",
      "Question 49+18   True 67   Guess 67   Good job\n",
      "Question 817+532 True 1349 Guess 1348 Fail\n",
      "Question 598+250 True 848  Guess 847  Fail\n",
      "Question 91+260  True 351  Guess 341  Fail\n",
      "Question 1+53    True 54   Guess 54   Good job\n",
      "Question 42+374  True 416  Guess 416  Good job\n",
      "Question 729+914 True 1643 Guess 1643 Good job\n",
      "Question 321+409 True 730  Guess 730  Good job\n",
      "Question 97+958  True 1055 Guess 1045 Fail\n",
      "Question 861+9   True 870  Guess 870  Good job\n",
      "Question 733+808 True 1541 Guess 1531 Fail\n",
      "Question 3+327   True 330  Guess 330  Good job\n",
      "Question 175+36  True 211  Guess 211  Good job\n",
      "Question 952+492 True 1444 Guess 1345 Fail\n",
      "Question 534+252 True 786  Guess 786  Good job\n",
      "Question 864+71  True 935  Guess 935  Good job\n",
      "Question 76+146  True 222  Guess 222  Good job\n",
      "Question 275+36  True 311  Guess 311  Good job\n",
      "The model scored  65.0  % in its test.\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 5):\n",
    "    print()  \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=20,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    print('Finished iteration ', iteration)\n",
    "    numcorrect = 0\n",
    "    numtotal = 20\n",
    "    \n",
    "    for i in range(numtotal):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Question', q, end=' ')\n",
    "        print('True', correct, end=' ')\n",
    "        print('Guess', guess, end=' ')\n",
    "        if guess == correct :\n",
    "          print('Good job')\n",
    "          numcorrect += 1\n",
    "        else:\n",
    "          print('Fail')\n",
    "         \n",
    "    print('The model scored ', numcorrect*100/numtotal,' % in its test.')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
